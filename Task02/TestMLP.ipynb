{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sigmoid(x):\n",
    "#     return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    if isinstance(x, list):\n",
    "        sigmoids = []\n",
    "        for value in x:\n",
    "            sigmoids.append(sigmoid(value))\n",
    "        return sigmoids\n",
    "    else:\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    if isinstance(x, list):\n",
    "        sigmoids_derivative = []\n",
    "        for value in x:\n",
    "            sigmoids_derivative.append(sigmoid_derivative(value))\n",
    "        return sigmoids_derivative\n",
    "    else:\n",
    "        s = sigmoid(x)\n",
    "        return s * (1 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example in the lecture 4\n",
    "\n",
    "X = np.array([0, 0, 1])\n",
    "\n",
    "Weights = [\n",
    "    np.array([\n",
    "        [0.21, 0.15, -0.3],\n",
    "        [0.10, 0.25, -0.4]\n",
    "    ]),\n",
    "    np.array([\n",
    "        [-0.2, 0.3, -0.4]\n",
    "    ])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights before [array([[ 0.21,  0.15, -0.3 ],\n",
      "       [ 0.1 , -0.4 ,  0.25]]), array([[-0.2,  0.3, -0.4]])]\n",
      "Epoch 0, Loss: 0.21867816773421128\n",
      "Epoch 70, Loss: 0.190577736203999\n",
      "Epoch 140, Loss: 0.1892680050245271\n",
      "Epoch 210, Loss: 0.1885409218985165\n",
      "Epoch 280, Loss: 0.1878078420290692\n",
      "Epoch 350, Loss: 0.18699998672063067\n",
      "Epoch 420, Loss: 0.18607037548151825\n",
      "Epoch 490, Loss: 0.1849620138086021\n",
      "Epoch 560, Loss: 0.18359999236876934\n",
      "Epoch 630, Loss: 0.18188571771689083\n",
      "Epoch 700, Loss: 0.17969304000314945\n",
      "Epoch 770, Loss: 0.17687059535136374\n",
      "Epoch 840, Loss: 0.17326029820598718\n",
      "Epoch 910, Loss: 0.16874898492714172\n",
      "Epoch 980, Loss: 0.1633691043054037\n",
      "Epoch 1050, Loss: 0.15742783649846692\n",
      "Epoch 1120, Loss: 0.15155799086332417\n",
      "Epoch 1190, Loss: 0.14655512112695962\n",
      "Epoch 1260, Loss: 0.14305706481970104\n",
      "Epoch 1330, Loss: 0.1413290038891512\n",
      "Epoch 1400, Loss: 0.141278303802803\n",
      "Epoch 1470, Loss: 0.14258478660569837\n",
      "Epoch 1540, Loss: 0.14482793861138965\n",
      "Epoch 1610, Loss: 0.14758355717281163\n",
      "Epoch 1680, Loss: 0.15049190220541903\n",
      "Epoch 1750, Loss: 0.15329381620920302\n",
      "Epoch 1820, Loss: 0.1558344116888022\n",
      "Epoch 1890, Loss: 0.1580442771655842\n",
      "Epoch 1960, Loss: 0.15991242402403139\n",
      "Weights after training: [array([[-3.01403433, -4.65567047, -0.52013545],\n",
      "       [-3.12403433, -5.20567047,  0.02986455]]), array([[-1.65507363, -3.14996453, -0.58507584]])]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Input vector\n",
    "X = np.array([0, 0, 1])  # Include bias as the last input\n",
    "y = np.array([0])\n",
    "\n",
    "# Weights for the layers\n",
    "Weights = [\n",
    "    np.array([\n",
    "        [0.21, 0.15, -0.3],\n",
    "        [0.10, -0.4, 0.25]\n",
    "    ]),\n",
    "    np.array([\n",
    "        [-0.2, 0.3, -0.4]\n",
    "    ])\n",
    "]\n",
    "activations = []\n",
    "sigmasList = []\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Feedforward function\n",
    "def feedForward(X):\n",
    "    global activations, nets\n",
    "    activations = [X] \n",
    "    nets = []\n",
    "    for i in range(len(Weights)):\n",
    "        # Compute the input for the current layer\n",
    "        layer_input = np.dot(activations[i], Weights[i].T)\n",
    "        nets.append(layer_input)\n",
    "        # print(\"layer_input\", layer_input)\n",
    "        \n",
    "        # Apply activation function (sigmoid for hidden layers, no activation for output layer)\n",
    "        layer_input = sigmoid(layer_input)\n",
    "        if i != len(Weights) - 1:  # If not the output layer\n",
    "            # Add bias to the next layer input\n",
    "            layer_input = np.append(layer_input, 1)\n",
    "        \n",
    "        # Append the result to the activations list\n",
    "        activations.append(layer_input)\n",
    "        # print(\"activations\", activations)\n",
    "        # print(\"nets = \", nets)\n",
    "        # print(\"nest shape : \", np.array(nets).shape)\n",
    "    \n",
    "    return activations[-1]  # Return the output of the final layer\n",
    "\n",
    "\n",
    "# print(feedForward(X))\n",
    "# # print(\"nets = \", nets)\n",
    "# print(\"activation\" ,activations)\n",
    "def backPropagation(X, y):\n",
    "    global sigmasList\n",
    "\n",
    "    # Feedforward\n",
    "    output_activation = feedForward(X)\n",
    "\n",
    "    sigmasList = []\n",
    "    sigmaOutput = (y - output_activation) * output_activation * (1 - output_activation)\n",
    "    # print(\"sigmaOutput\", sigmaOutput)\n",
    "\n",
    "    sigmas = sigmaOutput\n",
    "    for i in range(len(Weights)-1, 0, -1):\n",
    "        sigmasList.append(sigmas * Weights[i] * sigmoid_derivative(nets[i]))\n",
    "\n",
    "    sigmasList.reverse()\n",
    "    sigmasList.append(sigmaOutput)\n",
    "\n",
    "\n",
    "# backPropagation(X, 0, learning_rate=0.1)\n",
    "# print(\"Sigma\" , sigmasList)\n",
    "# under creation method\n",
    "def ModifyWeights(learningRate = 0.1, epoch=0):\n",
    "    if epoch > 1000:\n",
    "        learningRate = 0.01\n",
    "    for i, sigmas in enumerate(sigmasList):\n",
    "        Weights[i] = Weights[i] + learningRate * sigmas * activations[i]\n",
    "\n",
    "# print(\"Weights before\" , Weights)      \n",
    "# ModifyWeights(0.1)\n",
    "# print(\"Weights after\" , Weights)\n",
    "\n",
    "# Input vector\n",
    "X = np.array([[0, 0, 1], [0,1,1], [1,0,1], [1,1,1]])  # Include bias as the last input\n",
    "y = np.array([0, 0, 0, 1])\n",
    "\n",
    "def fit(X, y, epochs = 1000):\n",
    "    print(\"Weights before\" , Weights) \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        # Loop over each training sample\n",
    "        for i in range(X.shape[0]):\n",
    "            X_sample = X[i]\n",
    "            y_sample = y[i]\n",
    "\n",
    "            # Feedforward and backpropagation for each sample\n",
    "            feedForward(X_sample)\n",
    "            backPropagation(X_sample, y_sample)\n",
    "            ModifyWeights(0.1)  # Update weights after each sample\n",
    "\n",
    "            # Calculate loss (Mean Squared Error) for monitoring\n",
    "            output = activations[-1]\n",
    "            total_loss += np.mean((y_sample - output) ** 2)\n",
    "        \n",
    "        # Print the loss every 100 epochs\n",
    "        if epoch % 70 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {total_loss / X.shape[0]}')\n",
    "\n",
    "    print(\"Weights after training:\", Weights)\n",
    "\n",
    "    #     feedForward(X)\n",
    "    #     backPropagation(X, y)\n",
    "    #     ModifyWeights(0.01)\n",
    "    # print(\"Weights after\" , Weights)\n",
    "\n",
    "fit(X,y, 2000)\n",
    "\n",
    "# fit(np.array([0, 0, 1]), np.array([0]), 400)\n",
    "# fit(np.array([1, 0, 1]), np.array([0]), 600)\n",
    "# fit(np.array([0, 1, 1]), np.array([0]), 300)\n",
    "# fit(np.array([1, 1, 1]), np.array([1]), 500)\n",
    "\n",
    "# fit(np.array([0, 0, 0]), np.array([0]), 400)\n",
    "# fit(np.array([1, 0, 0]), np.array([0]), 600)\n",
    "# fit(np.array([0, 1, 0]), np.array([0]), 300)\n",
    "# fit(np.array([1, 1, 0]), np.array([1]), 500)\n",
    "\n",
    "def predict(X, bias=True):\n",
    "    # Perform a forward pass\n",
    "    biasEnable = 1 if bias else 0\n",
    "    X = np.append(X, biasEnable)\n",
    "    output = feedForward(X)\n",
    "\n",
    "\n",
    "    # for i in range(len(Weights)):\n",
    "    #     print(\"X.shape : \", X.shape)\n",
    "    #     print(f\"Weights[{i}].shape : \", Weights[i].shape)\n",
    "    #     biasEnable = 1 if bias else 0\n",
    "    #     X = np.append(X, biasEnable)\n",
    "    #     X = np.dot([X], Weights[i].T)\n",
    "    #     activation = sigmoid(X)\n",
    "    #     X = activation\n",
    "    #     print(f\"loop {i} passed!\")\n",
    "\n",
    "    # return activation\n",
    "\n",
    "    # Predicted class: index of the highest output neuron\n",
    "    predicted_class = np.argmax(output)\n",
    "    return predicted_class\n",
    "\n",
    "print(predict(np.array([0, 0])))\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are available\n",
    "\n",
    "def calculate_accuracy_and_confusion_matrix(X_train, y_train, X_test, y_test, bias=True):\n",
    "    # Initialize counters for accuracy and confusion matrix\n",
    "    correct_train = 0\n",
    "    correct_test = 0\n",
    "    total_train = len(X_train)\n",
    "    total_test = len(X_test)\n",
    "    \n",
    "    # Initialize confusion matrices\n",
    "    cm_train = np.zeros((3, 3), dtype=int)  # For 3 classes\n",
    "    cm_test = np.zeros((3, 3), dtype=int)\n",
    "\n",
    "    # Predictions on the training data\n",
    "    for i in range(total_train):\n",
    "        predicted = predict(X_train[i], bias)\n",
    "        actual = y_train[i]\n",
    "        if predicted == actual:\n",
    "            correct_train += 1\n",
    "        cm_train[actual][predicted] += 1\n",
    "    \n",
    "    # Predictions on the test data\n",
    "    for i in range(total_test):\n",
    "        predicted = predict(X_test[i], bias)\n",
    "        actual = y_test[i]\n",
    "        if predicted == actual:\n",
    "            correct_test += 1\n",
    "        cm_test[actual][predicted] += 1\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    train_accuracy = correct_train / total_train * 100\n",
    "    test_accuracy = correct_test / total_test * 100\n",
    "\n",
    "    # Print Results\n",
    "    print(f\"Training Accuracy: {train_accuracy:.2f}%\")\n",
    "    print(f\"Testing Accuracy: {test_accuracy:.2f}%\")\n",
    "    print(\"Training Confusion Matrix:\")\n",
    "    print(cm_train)\n",
    "    print(\"Testing Confusion Matrix:\")\n",
    "    print(cm_test)\n",
    "\n",
    "# Example usage with your data\n",
    "# Assuming X_train, y_train, X_test, y_test are NumPy arrays with training and test data\n",
    "calculate_accuracy_and_confusion_matrix(X_train, y_train, X_test, y_test, bias=True)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
